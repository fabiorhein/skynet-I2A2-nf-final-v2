"""Importador page for processing XML/PDF/image files."""
import json
import logging
import streamlit as st
from pathlib import Path
from datetime import datetime
import re
from zoneinfo import ZoneInfo
from typing import List, Dict, Any, Optional
from decimal import Decimal
import concurrent.futures

# Express√£o regular para formatos ISO b√°sicos (YYYY-MM-DD ou YYYY-MM-DDTHH:MM:SSZ)
ISO_DATE_PATTERN = re.compile(
    r"^\d{4}-\d{2}-\d{2}(?:[T ]\d{2}:\d{2}:\d{2}(?:Z|[+-]\d{2}:?\d{2})?)?$"
)


def convert_date_to_iso(date_value: Optional[Any]) -> Optional[str]:
    """Converte datas comuns (DD/MM/YYYY, DD/MM/YY) para ISO 8601.

    Mant√©m strings j√° em formato ISO e lida com objetos datetime.
    """

    if date_value is None:
        return None

    if isinstance(date_value, datetime):
        # Normaliza para UTC sem fra√ß√µes
        return date_value.strftime('%Y-%m-%dT%H:%M:%SZ')

    date_str = str(date_value).strip()
    if not date_str:
        return None

    # Mant√©m formatos ISO (YYYY-MM-DD ou YYYY-MM-DDTHH:MM:SSZ)
    if ISO_DATE_PATTERN.match(date_str):
        # Normaliza espa√ßos para 'T'
        return date_str.replace(' ', 'T')

    if '/' in date_str:
        parts = date_str.split('/')
        if len(parts) == 3:
            day, month, year_part = parts
            if not (day.isdigit() and month.isdigit()):
                return None

            year_part = year_part.strip()
            if len(year_part) == 2 and year_part.isdigit():
                year = int(year_part)
                year += 1900 if year >= 70 else 2000
            elif len(year_part) == 4 and year_part.isdigit():
                year = int(year_part)
            else:
                return None

            try:
                dt = datetime(year, int(month), int(day))
                return dt.strftime('%Y-%m-%dT00:00:00Z')
            except ValueError:
                return None

    return None


# Importa√ß√µes locais
from backend.agents import coordinator
from backend.tools.ocr_processor import ocr_text_to_document
from backend.database.storage_manager import storage_manager as storage
from .importador_utils import process_single_file, display_import_results, process_directory

# Configura√ß√£o do logger
logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('importador.log')
    ]
)


def _validate_document_data(data: any) -> bool:
    """Valida se os dados extra√≠dos est√£o no formato esperado."""
    if not isinstance(data, dict):
        st.error(f"Erro: Dados em formato inv√°lido. Esperado dicion√°rio, obtido {type(data).__name__}")
        return False

    required_fields = ['emitente', 'itens', 'total']
    missing = [field for field in required_fields if field not in data]
    if missing:
        st.error(f"Erro: Campos obrigat√≥rios ausentes: {', '.join(missing)}")
        return False

    if not isinstance(data.get('itens'), list):
        st.error("Erro: O campo 'itens' deve ser uma lista")
        return False

    return True

def _to_float(value: Any) -> float:
    """Converte diferentes formatos num√©ricos para float."""
    if value is None:
        return 0.0

    if isinstance(value, Decimal):
        return float(value)

    if isinstance(value, (int, float)):
        return float(value)

    if isinstance(value, str):
        clean = value.strip().replace('R$', '').replace(' ', '')
        if not clean:
            return 0.0
        if ',' in clean and '.' in clean:
            clean = clean.replace('.', '').replace(',', '.')
        elif ',' in clean:
            clean = clean.replace(',', '.')
        try:
            return float(clean)
        except ValueError:
            return 0.0

    return 0.0

def _prepare_document_record(uploaded, parsed, classification=None) -> dict:
    """Prepara o registro do documento para ser salvo."""
    if not isinstance(parsed, dict):
        raise ValueError("Dados do documento devem ser um dicion√°rio")

    # Extrair dados de valida√ß√£o da classifica√ß√£o, se dispon√≠vel
    validation = {}
    if classification and isinstance(classification, dict):
        validation = classification.get('validacao', {})

    # Obter o status de valida√ß√£o ou definir como 'pending' se n√£o houver
    validation_status = validation.get('status', 'pending')

    # Extrair dados do emitente
    emitente = parsed.get('emitente') or {}

    # Extrair dados do destinat√°rio, se dispon√≠vel
    destinatario = parsed.get('destinatario') or {}

    # Extrair dados de itens, se dispon√≠vel
    itens = parsed.get('itens') or []

    # Extrair totais, se dispon√≠vel
    totais = parsed.get('totals') or {}

    # Preparar dados do documento
    doc_data = {
        'file_name': str(uploaded.name if hasattr(uploaded, 'name') else 'documento_sem_nome.pdf'),
        'document_type': parsed.get('document_type', 'CTe' if 'cte' in str(uploaded.name).lower() else 'NFe'),
        'document_number': parsed.get('numero') or parsed.get('nNF') or parsed.get('nCT'),
        'issuer_cnpj': emitente.get('cnpj') or emitente.get('CNPJ'),
        'issuer_name': emitente.get('razao_social') or emitente.get('nome') or emitente.get('xNome', ''),
        'recipient_cnpj': (
            destinatario.get('cnpj')
            or destinatario.get('cnpj_cpf')
            or destinatario.get('CNPJ')
            or destinatario.get('CPF')
        ),
        'recipient_name': destinatario.get('razao_social') or destinatario.get('nome') or destinatario.get('xNome', ''),
        'issue_date': convert_date_to_iso(parsed.get('data_emissao') or parsed.get('dhEmi')),
        'total_value': _to_float(parsed.get('total') or totais.get('valorTotal') or 0.0),
        'cfop': parsed.get('cfop') or (itens[0].get('cfop') if itens else None),
        'extracted_data': parsed,
        'validation_status': validation_status,
        'validation_details': {
            'issues': validation.get('issues', []),
            'warnings': validation.get('warnings', []),
            'validations': validation.get('validations', {})
        },
        'classification': classification or {},
        'raw_text': parsed.get('raw_text', ''),
        'uploaded_at': datetime.now(ZoneInfo('UTC')).isoformat(),
        'processed_at': datetime.now(ZoneInfo('UTC')).isoformat(),
        # Adiciona metadados adicionais para facilitar buscas
        'metadata': {
            'has_issues': len(validation.get('issues', [])) > 0,
            'has_warnings': len(validation.get('warnings', [])) > 0,
            'item_count': len(itens),
            'document_subtype': parsed.get('tipoDocumento') or 'Outros'
        }
    }

    # Garante que todos os campos necess√°rios tenham valores padr√£o
    doc_data['document_type'] = doc_data.get('document_type') or 'Outros'
    doc_data['document_number'] = doc_data.get('document_number') or 'SEM_NUMERO'
    doc_data['issuer_cnpj'] = (doc_data.get('issuer_cnpj') or '').strip() or '00000000000000'
    doc_data['issuer_name'] = (doc_data.get('issuer_name') or '').strip() or 'Emitente n√£o identificado'
    doc_data['recipient_cnpj'] = (doc_data.get('recipient_cnpj') or '').strip() or None
    doc_data['recipient_name'] = (doc_data.get('recipient_name') or '').strip() or None
    doc_data['total_value'] = doc_data.get('total_value') or 0.0

    # Normaliza issue_date vazia como None
    doc_data['issue_date'] = doc_data.get('issue_date') or None

    return doc_data

def render(storage):
    """Render the importador page."""
    st.header('üì• Importador de Documentos Fiscais')
    st.caption('Intelig√™ncia artificial para processamento autom√°tico de documentos fiscais')

    # Informa√ß√µes sobre tipos de arquivo suportados
    with st.expander('üìã Tipos de arquivo suportados', expanded=False):
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            **Documentos Estruturados:**
            - **XML**: NF-e, NFC-e, CT-e, MDF-e
            - Extra√ß√£o autom√°tica de campos
            - Valida√ß√£o fiscal completa
            """)

        with col2:
            st.markdown("""
            **Documentos Digitais:**
            - **PDF**: Documentos escaneados
            - **JPG/PNG**: Imagens de documentos
            - OCR com IA para extra√ß√£o
            """)

    # √Årea de upload com melhor visual
    st.markdown("---")
    st.markdown("### üìÑ Upload de Documentos")
    st.info("""
**Aten√ß√£o:** Para substituir arquivos enviados, remova manualmente os arquivos antigos clicando no **'X'** ao lado do nome do arquivo antes de fazer um novo upload. 

*Esta √© uma limita√ß√£o do componente de upload do Streamlit: n√£o √© poss√≠vel limpar a lista de arquivos via c√≥digo.*
""")

    # Bot√£o para limpar todos os uploads (troca a chave do file_uploader)
    if 'uploader_key' not in st.session_state:
        st.session_state.uploader_key = 0
    clear_uploads = st.button('üóëÔ∏è Limpar uploads')
    if clear_uploads:
        st.session_state.uploader_key += 1

    # Upload m√∫ltiplo de arquivos
    # Upload m√∫ltiplo de arquivos
    uploaded_files = st.file_uploader(
        'Arraste ou selecione um ou mais arquivos',
        type=['xml', 'pdf', 'png', 'jpg', 'jpeg'],
        help='Selecione um ou mais documentos fiscais para processamento em lote.',
        accept_multiple_files=True,
        key=f'document_uploader_{st.session_state.uploader_key}'
    )
    if uploaded_files and len(uploaded_files) > 0:
        st.warning('Para fazer novo upload, limpe os arquivos atuais.')

    
    # Op√ß√£o para selecionar diret√≥rio (apenas para execu√ß√£o local)
    process_dir = st.checkbox('Processar diret√≥rio local (apenas para desenvolvimento)')
    dir_path = ''
    
    if process_dir:
        dir_path = st.text_input('Caminho do diret√≥rio (ex: /caminho/para/documentos)')
    
    # Bot√£o para processar diret√≥rio
    process_dir_btn = st.button('Processar Diret√≥rio') if process_dir and dir_path else False
    
    # Se n√£o h√° arquivos carregados e n√£o foi solicitado processamento de diret√≥rio
    if not uploaded_files and not process_dir_btn:
        st.info('üëÜ Selecione um ou mais arquivos ou um diret√≥rio para come√ßar o processamento autom√°tico.')
        
        # Mostrar dicas sobre o processamento em lote
        with st.expander("üí° Dicas para processamento em lote", expanded=False):
            st.markdown("""
            - **Arquivos suportados**: XML, PDF, JPG, PNG
            - **Tamanho m√°ximo por arquivo**: 200MB
            - **Processamento em paralelo**: At√© 4 arquivos simultaneamente
            - **Relat√≥rio de erros**: Um resumo √© exibido ao final
            - **Arquivos com problemas**: S√£o ignorados, permitindo que os demais sejam processados
            """)
            
        # Se√ß√£o para processar documentos existentes
        st.markdown("---")
        st.markdown("### üß† Processar Documentos Existentes")
        st.markdown("""
        **O que acontece ap√≥s o upload:**
        1. üîç **Extra√ß√£o**: IA extrai dados automaticamente
        2. üè∑Ô∏è **Classifica√ß√£o**: Identifica tipo e validade
        3. ‚úÖ **Valida√ß√£o**: Verifica conformidade fiscal
        4. üíæ **Armazenamento**: Salva com embeddings para busca
        """)

        # Se√ß√£o para processar documentos existentes
        st.markdown("---")
        st.markdown("### üß† Processar Documentos Existentes")

        col1, col2 = st.columns(2)

        with col1:
            if st.button('üîÑ Processar Todos os Documentos para RAG',
                        help='Processa todos os documentos salvos que ainda n√£o t√™m embeddings',
                        type='secondary'):
                if 'rag_service' in st.session_state and st.session_state.rag_service:
                    with st.spinner('üîÑ Processando todos os documentos para busca inteligente...'):
                        try:
                            import asyncio

                            # Buscar documentos que n√£o foram processados pelo RAG
                            all_docs = storage.get_fiscal_documents(page=1, page_size=1000)
                            docs_to_process = []

                            if hasattr(all_docs, 'items'):
                                for doc in all_docs.items:
                                    # Verificar se o documento j√° tem embeddings
                                    if doc.get('embedding_status') != 'completed':
                                        docs_to_process.append(doc)

                            if docs_to_process:
                                st.info(f'üìã Encontrados {len(docs_to_process)} documentos para processar')

                                async def process_all_rag():
                                    results = []
                                    for doc in docs_to_process:
                                        try:
                                            result = await st.session_state.rag_service.process_document_for_rag(doc)
                                            results.append((doc['id'], result))
                                        except Exception as e:
                                            results.append((doc['id'], {'success': False, 'error': str(e)}))
                                    return results

                                # Processar em background
                                rag_results = asyncio.run(process_all_rag())

                                # Mostrar resultados
                                success_count = sum(1 for _, result in rag_results if result.get('success', False))
                                error_count = len(rag_results) - success_count

                                if success_count > 0:
                                    st.success(f'‚úÖ {success_count} documentos processados com sucesso!')
                                if error_count > 0:
                                    st.warning(f'‚ö†Ô∏è {error_count} documentos tiveram problemas no processamento')

                                # Detalhes dos resultados
                                with st.expander('üìä Detalhes do Processamento', expanded=False):
                                    for doc_id, result in rag_results:
                                        if result.get('success', False):
                                            chunks = result.get('chunks_processed', 0)
                                            st.success(f'‚úÖ Documento {doc_id}: {chunks} chunks criados')
                                        else:
                                            error = result.get('error', 'Erro desconhecido')
                                            st.error(f'‚ùå Documento {doc_id}: {error}')

                            else:
                                st.info('‚ÑπÔ∏è Todos os documentos j√° est√£o processados para busca inteligente!')

                        except Exception as e:
                            st.error(f'Erro no processamento em lote: {str(e)}')
                else:
                    st.error('‚ùå Sistema RAG n√£o dispon√≠vel. Reinicie a aplica√ß√£o.')

        with col2:
            if st.button('üìà Verificar Status do RAG',
                        help='Mostra estat√≠sticas do sistema RAG',
                        type='secondary'):
                if 'rag_service' in st.session_state and st.session_state.rag_service:
                    try:
                        stats = st.session_state.rag_service.get_embedding_statistics()

                        if 'error' not in stats:
                            st.markdown("**üìä Estat√≠sticas do Sistema RAG:**")
                            col1, col2, col3 = st.columns(3)

                            with col1:
                                st.metric("Total de Chunks", f"{stats.get('total_chunks', 0):,}")
                            with col2:
                                st.metric("Documentos com Embeddings", f"{stats.get('documents_with_embeddings', 0):,}")
                            with col3:
                                st.metric("Total de Insights", f"{stats.get('total_insights', 0):,}")

                            # Status dos embeddings
                            status_dist = stats.get('embedding_status_distribution', {})
                            if status_dist:
                                with st.expander('üìã Status dos Embeddings', expanded=False):
                                    for status, count in status_dist.items():
                                        if status == 'completed':
                                            st.success(f'‚úÖ {status.title()}: {count} documentos')
                                        elif status == 'failed':
                                            st.error(f'‚ùå {status.title()}: {count} documentos')
                                        else:
                                            st.info(f'‚è≥ {status.title()}: {count} documentos')
                        else:
                            st.error(f"Erro ao carregar estat√≠sticas: {stats['error']}")

                    except Exception as e:
                        st.error(f'Erro ao carregar estat√≠sticas: {str(e)}')
                else:
                    st.error('‚ùå Sistema RAG n√£o dispon√≠vel')

        return

        # Processar diret√≥rio se solicitado
    if process_dir_btn and dir_path:
        try:
            uploaded_files = process_directory(dir_path)
            if not uploaded_files:
                st.warning("Nenhum arquivo compat√≠vel encontrado no diret√≥rio.")
                return
            st.success(f"{len(uploaded_files)} arquivos encontrados no diret√≥rio.")
        except Exception as e:
            st.error(f"Erro ao acessar diret√≥rio: {str(e)}")
            return
    
    # Se n√£o h√° arquivos para processar, retorna
    if not uploaded_files:
        return
        
    # Criar diret√≥rio tempor√°rio
    tmp_dir = Path('tmp_upload')
    tmp_dir.mkdir(exist_ok=True, parents=True)
    
    # Processar m√∫ltiplos arquivos
    if len(uploaded_files) > 1:
        with st.spinner(f'Processando {len(uploaded_files)} arquivos...'):
            # Usar ThreadPoolExecutor para processar arquivos em paralelo
            with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
                # Iniciar processamento de todos os arquivos
                future_to_file = {
                    executor.submit(
                        process_single_file, 
                        file, 
                        storage, 
                        tmp_dir,
                        _prepare_document_record,  # Passando a fun√ß√£o como par√¢metro
                        _validate_document_data    # Passando a fun√ß√£o como par√¢metro
                    ): file 
                    for file in uploaded_files
                }
                
                # Coletar resultados conforme s√£o conclu√≠dos
                results = []
                rag_tasks = []
                progress_bar = st.progress(0)
                
                for i, future in enumerate(concurrent.futures.as_completed(future_to_file)):
                    try:
                        result = future.result()
                        results.append(result)
                        
                        # Se o documento foi salvo com sucesso e o RAG est√° dispon√≠vel
                        if result.get('success') and 'rag_service' in st.session_state and st.session_state.rag_service:
                            document_id = result.get('document_id')
                            if document_id:
                                # Criar uma tarefa RAG para ser executada ap√≥s o processamento
                                async def process_rag_task(doc_id):
                                    try:
                                        doc_for_rag = storage.get_fiscal_documents(id=doc_id, page=1, page_size=1)
                                        if doc_for_rag and hasattr(doc_for_rag, 'items') and doc_for_rag.items:
                                            return await st.session_state.rag_service.process_document_for_rag(doc_for_rag.items[0])
                                        return {'success': False, 'error': 'Documento n√£o encontrado para processamento RAG'}
                                    except Exception as e:
                                        logger.error(f"Erro no processamento RAG para documento {doc_id}: {e}")
                                        return {'success': False, 'error': str(e)}
                                
                                # Adicionar a tarefa √† lista
                                rag_tasks.append(process_rag_task(document_id))
                                
                    except Exception as e:
                        file = future_to_file[future]
                        results.append({
                            'file_name': file.name,
                            'success': False,
                            'error': str(e),
                            'document_id': None,
                            'document_type': None,
                            'validation_status': 'error'
                        })
                    
                    # Atualizar barra de progresso
                    progress = (i + 1) / len(uploaded_files)
                    progress_bar.progress(progress)
            
                # Executar tarefas RAG em paralelo, se houver
                if rag_tasks:
                    with st.spinner('Processando documentos para busca sem√¢ntica...'):
                        import asyncio
                        
                        # Criar um novo loop de eventos para executar as tarefas RAG
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        
                        try:
                            # Executar todas as tarefas RAG em paralelo
                            rag_results = loop.run_until_complete(asyncio.gather(*rag_tasks, return_exceptions=True))
                            
                            # Atualizar status dos documentos processados pelo RAG
                            for i, rag_result in enumerate(rag_results):
                                if isinstance(rag_result, dict) and 'success' in rag_result:
                                    if rag_result['success']:
                                        logger.info(f"Documento {i+1} processado com sucesso pelo RAG")
                                    else:
                                        logger.warning(f"Falha ao processar documento {i+1} no RAG: {rag_result.get('error', 'Erro desconhecido')}")
                                else:
                                    logger.error(f"Erro inesperado ao processar documento {i+1} no RAG: {rag_result}")
                            
                        except Exception as e:
                            logger.error(f"Erro ao executar processamento RAG em lote: {e}")
                        finally:
                            loop.close()
            
            # Exibir resultados
            display_import_results(results)
            
            # Limpar diret√≥rio tempor√°rio
            try:
                for file in tmp_dir.glob('*'):
                    file.unlink()
                tmp_dir.rmdir()
            except Exception as e:
                logger.warning(f"N√£o foi poss√≠vel limpar diret√≥rio tempor√°rio: {e}")
                
            return
    
    # Processar arquivo √∫nico (comportamento original)
    uploaded = uploaded_files[0]
    
    # Salvar arquivo temporariamente
    dest = tmp_dir / uploaded.name
    
    try:
        with open(dest, 'wb') as f:
            f.write(uploaded.getbuffer())
    except Exception as e:
        st.error(f'Erro ao salvar arquivo tempor√°rio: {str(e)}')
        return

    file_type = dest.suffix.lower()

    with st.spinner(f'Processando {file_type.upper()}...'):
        try:
            # Extract data based on file type
            if file_type == '.xml':
                parsed = coordinator.run_task('extract', {'path': str(dest)})

                if not _validate_document_data(parsed):
                    return

                st.subheader('‚úÖ Dados extra√≠dos')
                with st.expander('Visualizar dados extra√≠dos', expanded=False):
                    st.json(parsed)

                # Classify document
                with st.spinner('Classificando documento...'):
                    classification = coordinator.run_task('classify', {'parsed': parsed})
                    st.subheader('üè∑Ô∏è Classifica√ß√£o')
                    st.json(classification)

                # Exibir resultados da valida√ß√£o
                validation = classification.get('validacao', {})

                # Mostrar status da valida√ß√£o
                status = validation.get('status', 'unknown')
                status_emoji = {
                    'success': '‚úÖ',
                    'warning': '‚ö†Ô∏è',
                    'error': '‚ùå',
                    'pending': '‚è≥'
                }.get(status, '‚ùì')

                st.subheader(f'{status_emoji} Status da Valida√ß√£o: {status.upper()}')

                # Mostrar problemas e avisos
                col1, col2 = st.columns(2)

                with col1:
                    if validation.get('issues'):
                        with st.expander(f'‚ùå {len(validation["issues"])} Problemas Encontrados', expanded=True):
                            for issue in validation['issues']:
                                st.error(issue)
                    else:
                        st.success('‚úÖ Nenhum problema cr√≠tico encontrado')

                with col2:
                    if validation.get('warnings'):
                        with st.expander(f'‚ö†Ô∏è {len(validation["warnings"])} Avisos', expanded=False):
                            for warning in validation['warnings']:
                                st.warning(warning)
                    else:
                        st.info('‚ÑπÔ∏è Nenhum aviso')

                # Mostrar detalhes da valida√ß√£o
                with st.expander('üîç Detalhes da Valida√ß√£o', expanded=False):
                    validations = validation.get('validations', {})

                    # Valida√ß√£o do Emitente
                    if 'emitente' in validations:
                        st.subheader('Emitente')
                        emit = validations['emitente']
                        cols = st.columns(2)
                        cols[0].metric("CNPJ V√°lido", "‚úÖ Sim" if emit.get('cnpj') else "‚ùå N√£o")
                        cols[1].metric("Raz√£o Social", "‚úÖ Informada" if emit.get('razao_social') else "‚ö†Ô∏è Ausente")

                    # Valida√ß√£o de Itens
                    if 'itens' in validations:
                        st.subheader('Itens')
                        itens = validations['itens']
                        cols = st.columns(2)
                        cols[0].metric("Itens Encontrados",
                                    f"‚úÖ {len(parsed.get('itens', []))}" if itens.get('has_items') else "‚ùå Nenhum")
                        cols[1].metric("Itens V√°lidos",
                                    "‚úÖ Todos" if itens.get('all_valid') else "‚ö†Ô∏è Alguns itens inv√°lidos")

                    # Valida√ß√£o de Totais
                    if 'totals' in validations:
                        st.subheader('Totais')
                        totais = validations['totals']
                        if totais.get('valid') is not None:
                            if totais['valid']:
                                st.success("‚úÖ Soma dos itens confere com o total do documento")
                            else:
                                st.error(f"‚ùå Diferen√ßa de R$ {abs(totais.get('document_total', 0) - totais.get('calculated_total', 0)):.2f} nos totais")

                # Preparar e salvar o documento
                try:
                    record = _prepare_document_record(uploaded, parsed, classification)
                    saved = storage.save_fiscal_document(record)

                    # Debug: Exibir a estrutura da resposta salva
                    logger.info(f"Resposta do save_document: {saved}")

                    # Fun√ß√£o auxiliar para extrair ID de forma robusta
                    def extract_document_id(response):
                        """Extrai o ID do documento da resposta de forma robusta."""
                        if not response:
                            return None

                        # Se for um dicion√°rio
                        if isinstance(response, dict):
                            # Tenta chaves comuns
                            for key in ['id', 'ID', 'document_id', 'doc_id', 'fiscal_document_id']:
                                if key in response and response[key]:
                                    return str(response[key]).strip()

                            # Tenta em estruturas aninhadas
                            if 'data' in response and isinstance(response['data'], dict):
                                for key in ['id', 'ID', 'document_id', 'doc_id', 'fiscal_document_id']:
                                    if key in response['data'] and response['data'][key]:
                                        return str(response['data'][key]).strip()

                            # Se data for uma lista
                            if 'data' in response and isinstance(response['data'], list) and response['data']:
                                first_item = response['data'][0]
                                if isinstance(first_item, dict):
                                    for key in ['id', 'ID', 'document_id', 'doc_id', 'fiscal_document_id']:
                                        if key in first_item and first_item[key]:
                                            return str(first_item[key]).strip()

                        # Se for uma lista
                        elif isinstance(response, list) and response:
                            first_item = response[0]
                            if isinstance(first_item, dict):
                                for key in ['id', 'ID', 'document_id', 'doc_id', 'fiscal_document_id']:
                                    if key in first_item and first_item[key]:
                                        return str(first_item[key]).strip()

                        return None

                    # Extrai o ID usando a fun√ß√£o auxiliar
                    document_id = extract_document_id(saved)
                    logger.info(f"ID do documento obtido: {document_id}")

                    # RAG Processing - Processar documento automaticamente para RAG
                    if document_id:
                        try:
                            # Buscar o documento completo do banco para o RAG
                            full_document = storage.get_fiscal_documents(
                                id=document_id,
                                page=1,
                                page_size=1
                            )

                            if full_document and hasattr(full_document, 'items') and full_document.items:
                                doc_for_rag = full_document.items[0]

                                # Chamar RAG service em background
                                with st.spinner('üß† Processando documento para busca inteligente...'):
                                    # Usar o RAG service da sess√£o se dispon√≠vel
                                    if 'rag_service' in st.session_state and st.session_state.rag_service:
                                        import asyncio

                                        # Executar processamento RAG em background
                                        async def process_rag():
                                            try:
                                                result = await st.session_state.rag_service.process_document_for_rag(doc_for_rag)
                                                return result
                                            except Exception as rag_error:
                                                logger.error(f"Erro no processamento RAG: {rag_error}")
                                                return {'success': False, 'error': str(rag_error)}

                                        # Executar a fun√ß√£o ass√≠ncrona
                                        rag_result = asyncio.run(process_rag())

                                        if rag_result.get('success', False):
                                            chunks_count = rag_result.get('chunks_processed', 0)
                                            st.success(f'‚úÖ Documento processado para busca inteligente! ({chunks_count} chunks criados)')
                                            logger.info(f"RAG processing completed for document {document_id}: {chunks_count} chunks")
                                        else:
                                            error_msg = rag_result.get('error', 'Erro desconhecido')
                                            st.warning(f'‚ö†Ô∏è Documento salvo, mas houve um problema no processamento inteligente: {error_msg}')
                                            logger.error(f"RAG processing failed for document {document_id}: {error_msg}")
                                    else:
                                        st.info('‚ÑπÔ∏è Sistema RAG n√£o dispon√≠vel no momento. Documento salvo sem processamento inteligente.')
                                        logger.warning(f"RAG service not available for document {document_id}")
                            else:
                                st.warning('‚ö†Ô∏è N√£o foi poss√≠vel recuperar o documento completo para processamento RAG')
                                logger.warning(f"Could not retrieve full document for RAG processing: {document_id}")

                        except Exception as rag_error:
                            st.warning(f'‚ö†Ô∏è Erro no processamento inteligente: {str(rag_error)}')
                            logger.error(f"RAG processing error for document {document_id}: {rag_error}")

                    # Se n√£o conseguiu obter o ID do documento
                    elif not document_id:
                        logger.warning('Documento salvo, mas n√£o foi poss√≠vel obter o ID para processamento RAG.')
                        logger.warning(f'Resposta completa do save_document: {saved}')

                    # Debug: Exibir o ID do documento salvo
                    if document_id:
                        st.info(f'üìÑ **ID do documento:** `{document_id}`')
                    else:
                        st.warning('‚ö†Ô∏è N√£o foi poss√≠vel obter o ID do documento salvo. Verifique os logs para mais detalhes.')

                    # Mostrar resumo do processamento
                    with st.expander('üìä Resumo do Processamento', expanded=False):
                        col1, col2 = st.columns(2)

                        with col1:
                            total_value = _to_float(record.get('total_value', 0))
                            st.markdown(f"""
                            **Informa√ß√µes Extra√≠das:**
                            - **Tipo:** {record.get('document_type', 'N/A')}
                            - **N√∫mero:** {record.get('document_number', 'N/A')}
                            - **Valor:** R$ {total_value:.2f}
                            """)

                        with col2:
                            validation_status = record.get('validation_status', 'pending')
                            status_icon = {'success': '‚úÖ', 'warning': '‚ö†Ô∏è', 'error': '‚ùå', 'pending': '‚è≥'}.get(validation_status, '‚ùì')
                            st.markdown(f"""
                            **Status da Valida√ß√£o:**
                            - **Status:** {status_icon} {validation_status.upper()}
                            - **Itens:** {len(record.get('extracted_data', {}).get('itens', []))}
                            - **Processado:** {datetime.now().strftime('%d/%m/%Y %H:%M')}
                            """)

                except Exception as e:
                    st.error(f'Erro ao salvar documento: {str(e)}')
                    st.exception(e)  # Show full traceback in logs

            else:  # PDF/Image
                st.info('Processando documento n√£o-XML via OCR...')
                parsed = coordinator.run_task('extract', {'path': str(dest)})

                # Tratamento de erros com mensagens claras
                if isinstance(parsed, dict) and parsed.get('error'):
                    error_code = parsed.get('error', 'unknown')
                    error_message = parsed.get('message', 'Erro desconhecido na extra√ß√£o')

                    if error_code == 'empty_ocr':
                        st.error(f'''
                            ‚ùå N√£o foi poss√≠vel extrair texto do documento.

                            Motivo: {error_message}

                            Verifique se:
                            - O documento est√° leg√≠vel e em boa qualidade
                            - O PDF cont√©m texto selecion√°vel (n√£o √© apenas imagem)
                            - O Poppler est√° instalado (para PDFs escaneados)
                            - A imagem tem resolu√ß√£o suficiente
                        ''')
                    elif error_code == 'tesseract_not_installed':
                        st.error(f'''
                            ‚ùå Tesseract OCR n√£o est√° dispon√≠vel

                            {error_message}

                            **Instru√ß√µes de instala√ß√£o:**
                            - **Windows:** Baixe em https://github.com/UB-Mannheim/tesseract/wiki
                            - **Linux:** `sudo apt-get install tesseract-ocr`
                            - **macOS:** `brew install tesseract`

                            Ap√≥s instalar, reinicie a aplica√ß√£o.
                        ''')
                    elif error_code == 'invalid_image_format':
                        st.error(f"‚ùå Formato de imagem inv√°lido: {error_message}")
                    elif error_code == 'file_not_found':
                        st.error(f"‚ùå Arquivo n√£o encontrado: {error_message}")
                    elif error_code == 'unsupported_file_type':
                        st.error(f"‚ùå Tipo de arquivo n√£o suportado: {error_message}")
                    else:
                        st.error(f"‚ùå Erro na extra√ß√£o ({error_code}): {error_message}")

                    logger.error(f"Erro de extra√ß√£o: {error_code} - {error_message}")
                    return

                # Valida√ß√£o adicional
                if not isinstance(parsed, dict):
                    st.error(f"‚ùå Resposta inv√°lida da extra√ß√£o: {type(parsed).__name__}")
                    logger.error(f"Resposta inv√°lida: {parsed}")
                    return

                # Show raw OCR text with better formatting
                st.subheader('üìù Texto extra√≠do (OCR)')
                raw_text = parsed.get('raw_text', '').strip()

                if not raw_text:
                    st.warning('Nenhum texto foi extra√≠do do documento.')
                    return

                with st.expander('Visualizar texto extra√≠do', expanded=False):
                    st.text_area(
                        'Texto extra√≠do (apenas leitura)',
                        value=raw_text[:5000] + ('...' if len(raw_text) > 5000 else ''),
                        height=200,
                        disabled=True
                    )

                # Processamento autom√°tico com IA
                with st.spinner('Processando texto com IA para extra√ß√£o estruturada...'):
                    try:
                        # Usar IA para extrair campos automaticamente
                        extracted_data = ocr_text_to_document(raw_text, use_llm=True)

                        # Garantir que extracted_data √© um dicion√°rio
                        if not isinstance(extracted_data, dict):
                            st.error('Erro: Dados extra√≠dos n√£o est√£o no formato esperado')
                            st.stop()

                        # Adicionar o texto bruto extra√≠do
                        extracted_data['raw_text'] = raw_text

                        # Se n√£o conseguiu extrair dados suficientes, tentar com heur√≠stica
                        if not extracted_data.get('emitente') or not extracted_data.get('itens'):
                            st.warning('IA n√£o conseguiu extrair todos os campos automaticamente. Tentando com heur√≠stica...')
                            extracted_data = ocr_text_to_document(raw_text, use_llm=False)

                            # Garantir que os dados extra√≠dos s√£o v√°lidos
                            if not isinstance(extracted_data, dict):
                                st.error('Erro: Falha ao extrair dados usando heur√≠stica')
                                st.stop()

                            extracted_data['raw_text'] = raw_text

                        # Classificar o documento
                        classification = coordinator.run_task('classify', {'parsed': extracted_data})

                        try:
                            # Validar os dados extra√≠dos antes de salvar
                            if not _validate_document_data(extracted_data):
                                st.error('Erro: Dados extra√≠dos n√£o cont√™m campos obrigat√≥rios')
                                st.stop()

                            # Preparar e salvar o registro
                            record = _prepare_document_record(uploaded, extracted_data, classification)

                            # Validar o registro antes de salvar
                            required_fields = ['file_name', 'document_type', 'extracted_data', 'raw_text']
                            missing_fields = [field for field in required_fields if field not in record]
                            if missing_fields:
                                st.error(f'Erro: Registro inv√°lido. Campos faltando: {missing_fields}')
                                st.stop()

                            # Garantir que extracted_data √© serializ√°vel
                            try:
                                json.dumps(record['extracted_data'])
                            except (TypeError, OverflowError) as e:
                                st.error(f'Erro: Dados extra√≠dos cont√™m valores n√£o serializ√°veis: {str(e)}')
                                st.stop()

                            # Salvar o documento
                            saved = storage.save_fiscal_document(record)

                            # Verificar se o documento foi salvo com sucesso
                            if not isinstance(saved, dict) or 'id' not in saved:
                                error_msg = str(saved) if not isinstance(saved, dict) else 'Resposta do servidor n√£o cont√©m ID do documento'
                                st.error(f'Erro ao salvar documento: {error_msg}')
                                if hasattr(storage, '_last_error'):
                                    st.error(f'Detalhes do erro: {getattr(storage, "_last_error", "")}')
                                st.stop()

                            # Documento salvo com sucesso
                            st.success('‚úÖ Documento salvo com sucesso!')
                            st.balloons()

                            # RAG Processing - Processar documento automaticamente para RAG
                            if 'id' in saved:
                                document_id = saved['id']
                                try:
                                    # Chamar RAG service em background
                                    with st.spinner('üß† Processando documento para busca inteligente...'):
                                        # Usar o RAG service da sess√£o se dispon√≠vel
                                        if 'rag_service' in st.session_state and st.session_state.rag_service:
                                            import asyncio

                                            # Executar processamento RAG em background
                                            async def process_rag():
                                                try:
                                                    result = await st.session_state.rag_service.process_document_for_rag(saved)  # ‚úÖ Usar documento salvo com ID correto
                                                    return result
                                                except Exception as rag_error:
                                                    logger.error(f"Erro no processamento RAG: {rag_error}")
                                                    return {'success': False, 'error': str(rag_error)}

                                            # Executar a fun√ß√£o ass√≠ncrona
                                            rag_result = asyncio.run(process_rag())

                                            if rag_result.get('success', False):
                                                chunks_count = rag_result.get('chunks_processed', 0)
                                                st.success(f'‚úÖ Documento processado para busca inteligente! ({chunks_count} chunks criados)')
                                                logger.info(f"RAG processing completed for document {document_id}: {chunks_count} chunks")
                                            else:
                                                error_msg = rag_result.get('error', 'Erro desconhecido')
                                                st.warning(f'‚ö†Ô∏è Documento salvo, mas houve um problema no processamento inteligente: {error_msg}')
                                                logger.error(f"RAG processing failed for document {document_id}: {error_msg}")
                                        else:
                                            st.info('‚ÑπÔ∏è Sistema RAG n√£o dispon√≠vel no momento. Documento salvo sem processamento inteligente.')
                                            logger.warning(f"RAG service not available for document {document_id}")

                                except Exception as rag_error:
                                    st.warning(f'‚ö†Ô∏è Erro no processamento inteligente: {str(rag_error)}')
                                    logger.error(f"RAG processing error for document {document_id}: {rag_error}")

                            # Salvar hist√≥rico se suportado
                            try:
                                if hasattr(storage, 'save_history'):
                                    history_data = {
                                        'fiscal_document_id': saved.get('id'),
                                        'event_type': 'created',
                                        'event_data': {
                                            'source': 'ocr_auto',
                                            'file_type': file_type,
                                            'validation_status': record.get('validation_status')
                                        }
                                    }
                                    storage.save_history(history_data)
                            except Exception as history_error:
                                st.warning(f'Aviso: N√£o foi poss√≠vel salvar o hist√≥rico: {str(history_error)}')

                            # Mostrar dados extra√≠dos
                            st.subheader('üìä Dados extra√≠dos automaticamente')
                            st.json(extracted_data)

                            # Mostrar link para visualizar o documento salvo
                            if 'id' in saved:
                                st.markdown(f'''
                                **A√ß√µes:**
                                - [Visualizar documento](#)
                                - [Editar informa√ß√µes](#)
                                ''', unsafe_allow_html=True)

                            # Mostrar resumo do processamento OCR
                            with st.expander('üîç Detalhes do OCR', expanded=False):
                                st.markdown(f"""
                                **Processamento OCR:**
                                - **Arquivo:** {uploaded.name}
                                - **Tipo:** {file_type.upper()}
                                - **Texto extra√≠do:** {len(raw_text)} caracteres
                                - **Campos identificados:** {len(extracted_data)} campos
                                - **Status:** Processamento conclu√≠do com IA
                                """)

                        except Exception as e:
                            st.error(f'Erro ao salvar documento: {str(e)}')
                            st.exception(e)  # Log detalhado no console

                    except Exception as e:
                        st.error(f'Erro ao processar documento automaticamente: {str(e)}')
                        st.exception(e)

        except Exception as e:
            st.error(f'‚ùå Ocorreu um erro inesperado: {str(e)}')
            st.exception(e)  # Show full traceback in logs

        finally:
            # Clean up temporary file
            try:
                if dest.exists():
                    dest.unlink()
            except Exception as e:
                st.warning(f'Aviso: N√£o foi poss√≠vel remover o arquivo tempor√°rio: {str(e)}')

    # Update session state
    if 'processed_documents' in st.session_state:
        try:
            result = storage.get_fiscal_documents(page=1, page_size=1000)
            # Acessa items diretamente do objeto PaginatedResponse
            st.session_state.processed_documents = result.items if hasattr(result, 'items') else []
            
            # Se estamos processando um √∫nico arquivo, rolar para a se√ß√£o de resultados
            if len(uploaded_files) == 1:
                st.markdown("---")
                st.markdown("### üìù Resultado do Processamento")
                
        except Exception as e:
            st.warning('N√£o foi poss√≠vel atualizar a lista de documentos.')
            st.exception(e)  # Show full traceback in logs
